ЧЕК-ЛИСТ СООТВЕТСТВИЯ ПРОЕКТА РЕКОМЕНДАЦИЯМ ИБ / SBERINFRA

Формат:
- **Требование / рекомендация** – формулировка из статей/переписки.
- **Статус** – `РЕАЛИЗОВАНО`, `ЧАСТИЧНО`, `В БЭКЛОГЕ`.
- **Как реализовано / что планируется** – краткое описание, с привязкой к файлам/функциям.

======================================================================
1. Общая модель сопровождения (RLM, минимизация root/sudo)
======================================================================

1.1. *«Выполняйте обслуживание сервера через RLM…»*
- **Статус**: РЕАЛИЗОВАНО (по текущему дизайну)
- **Как реализовано**:
  - Установка RPM для Prometheus, Grafana, Harvest выполняется через RLM‑сценарий `LINUX_RPM_INSTALLER`, а не напрямую из скрипта.
  - Скрипт `deploy_monitoring_script.sh` опирается на уже установленные пакеты и только настраивает конфигурацию и интеграции (Vault, RLM API, Grafana API, Harvest).
  - Создание сервисных УЗ и групп для Vault (`${KAE}-lnx-va-start`, `${KAE}-lnx-va-read`) и мониторинга (`${KAE}-lnx-mon_*`) выполняется через IDM/RLM, а не внутри скрипта.

1.2. *«Модель сопровождения АС должна следовать принципу \"наименьших полномочий\"…»*
- **Статус**: ЧАСТИЧНО
- **Как реализовано**:
  - Опасные операции (iptables, curl к внешним API, запись системных конфигов) выполняются не произвольными командами, а через обёртки с валидацией и hash‑контролем (`wrappers/*.sh` + `*_launcher.sh`).
  - Для run‑time управления стеком внедрены user‑юниты под сервисной УЗ `${KAE}-lnx-mon_sys`, запуск и рестарт сервисов возможен через `systemctl --user` без root (см. функции `setup_monitoring_user_units`, `configure_services`).
  - В рабочем sudoers нет правил вида `ALL=(ALL:ALL) ALL`, нет прав на одиночные команды `pwd`, `ps`, `hostname`, `id`, `grep` и т.п.
- **Что остаётся**:
  - Для PROD окончательно закрепить модель: RLM делает установку/удаление RPM и системных юнитов, а прикладной скрипт и CI работают только через user‑юниты и прикладные каталоги.

======================================================================
2. SUDO, NOEXEC, запрет переменных, awk/sed/curl/cat в sudoers
======================================================================

2.1. *«Нельзя использовать переменные и `*` в правилах sudoers…»*
- **Статус**: РЕАЛИЗОВАНО
- **Как реализовано**:
  - Рабочий `sudoers` содержит одно правило с конкретным путём к скрипту, без переменных и звёздочек, например:
    - `ALL=(ALL:ALL) NOEXEC: NOPASSWD: /bin/bash /tmp/deploy-monitoring/deploy_monitoring_script.sh` (`sudoers`).
  - Исторические примеры с переменными/`*` в sudoers (iptables, curl, cat с `"$VAR"`) убраны из рабочих конфигов и оставлены только как «как не надо» в `sudoers.txt`.

2.2. *«NOEXEC должен быть в правилах sudo…»*
- **Статус**: РЕАЛИЗОВАНО
- **Как реализовано**:
  - В рабочем правиле sudo явно указан атрибут `NOEXEC` перед `NOPASSWD`.

2.3. *«awk/sed/curl/cat не должны быть в sudoers, а только в явных обёртках/скриптах…»*
- **Статус**: РЕАЛИЗОВАНО
- **Как реализовано**:
  - В sudoers **нет** правил с `awk`, `sed`, `curl`, `cat`, `iptables-save`, `journalctl` и т.п.
  - Эти утилиты используются только:
    - внутри `deploy_monitoring_script.sh` (один запуск под root по строго ограниченному sudo‑правилу);
    - внутри обёрток `iptables_wrapper.sh`, `rlm_task_wrapper.sh`, `grafana_wrapper.sh`, `config_writer.sh`.

2.4. *«curl запрещён, кроме whitelisted сервисов и только через обёртку»*
- **Статус**: РЕАЛИЗОВАНО
- **Как реализовано**:
  - Любой curl к **RLM API** идёт только через `wrappers/rlm_task_wrapper.sh`, который:
    - проверяет `RLM_API_URL` по whitelist’у (`ALLOWED_RLM_BASES`);
    - валидирует токен и `task_id`;
    - поддерживает только `POST /api/tasks.json` и `GET /api/tasks/<id>/`.
  - Любой curl к **Grafana API и HTTP‑проверкам** идёт только через `wrappers/grafana_wrapper.sh`, который:
    - ограничивает URL видами `https://<host>:3000/...` и `http(s)://127.0.0.1:<port>`;
    - валидирует токены/логин‑пароль/ID;
    - не даёт ходить на произвольные адреса.
  - В `deploy_monitoring_script.sh` **нет прямых curl**, только вызовы обёрток.

2.5. *«/usr/bin/journalctl – вместо sudo прав на команду добавьте УЗ в группу systemd-journal»*
- **Статус**: ЧАСТИЧНО (зависит от админов ОС)
- **Как реализовано/планируется**:
  - Скрипт не запрашивает sudo‑прав на `journalctl`.
  - Для чтения логов Vault/сервисов предполагается добавлять нужные УЗ в группу `systemd-journal` на стороне админов ОС / через RLM.
  - В `SECURITY_IB_NOTES.md` планируется отдельный раздел с этой рекомендацией.

======================================================================
3. Белые списки, валидация параметров, обёртки + hash-контроль
======================================================================

3.1. *«Все команды, работающие с файлами, должны быть явно прописаны или через обёртку с валидацией»*
- **Статус**: РЕАЛИЗОВАНО / ЧАСТИЧНО
- **Как реализовано**:
  - Запись конфигов и состояния выполняется только через `wrappers/config_writer.sh`, который:
    - содержит белый список допустимых путей (`/etc/environment.d/99-monitoring-vars.conf`, `/opt/vault/conf/agent.hcl`, `/etc/grafana/grafana.ini`, `/etc/prometheus/web-config.yml`, `/etc/prometheus/prometheus.env`, `/etc/profile.d/harvest.sh`, `/opt/harvest/harvest.yml`, `/etc/systemd/system/harvest.service`, `/etc/prometheus/prometheus.yml`, `/var/lib/monitoring_deployment_state`);
    - при любом ином пути немедленно завершает работу с ошибкой.
  - Настройка iptables выполняется через `wrappers/iptables_wrapper.sh`, который:
    - валидирует порты (1–65535) и формат IP;
    - использует только фиксированные бинарники `/usr/sbin/iptables`, `/usr/sbin/ip6tables`, `/usr/sbin/iptables-save`.
  - Работа с RLM и Grafana API – только через `rlm_task_wrapper.sh` и `grafana_wrapper.sh`.
- **Что остаётся**:
  - В `cleanup_all_previous()` пока есть `rm -rf` по системным путям (`/etc/prometheus`, `/etc/grafana`, `/usr/lib/systemd/system/...`, `/usr/share/...`). Это рабочее, но с точки зрения ИБ должно быть вынесено в отдельный RLM‑сценарий «очистки/переустановки мониторинга».

3.2. *«Скрипты‑обёртки должны иметь контроль хеша (sha256)»*
- **Статус**: РЕАЛИЗОВАНО
- **Как реализовано**:
  - `wrappers/generate_launchers.sh` создаёт:
    - `iptables_launcher.sh`, `rlm_launcher.sh`, `grafana_launcher.sh`, `config_writer_launcher.sh`.
  - Каждый лаунчер:
    - содержит константу `EXPECTED_HASH` (`sha256sum` соответствующей обёртки);
    - при запуске пересчитывает `sha256` и сравнивает;
    - при несовпадении завершает выполнение с ошибкой и пишет `[SECURITY] Hash mismatch for ...`.
  - В `deploy_monitoring_script.sh` вызываются именно `*_launcher.sh`, а не сами обёртки.

======================================================================
4. User-юниты systemd и модель ролей (mon_sys / mon_ci / mon_admin / mon_ro)
======================================================================

4.1. *«Перейти на user‑юниты вместо системных сервисов под root»*
- **Статус**: ЧАСТИЧНО
- **Как реализовано**:
  - В `deploy_monitoring_script.sh` добавлена функция `setup_monitoring_user_units`, которая:
    - вычисляет `KAE` из `NAMESPACE_CI` (`CIxxxx_CIyyyy → KAE=CIyyyy`);
    - формирует имя сервисной УЗ мониторинга `${KAE}-lnx-mon_sys`;
    - находит домашний каталог `${KAE}-lnx-mon_sys` через `getent passwd`;
    - создаёт каталог `~${KAE}-lnx-mon_sys/.config/systemd/user`;
    - генерирует user‑юниты:
      - `monitoring-prometheus.service` – использует уже сформированный `/etc/prometheus/prometheus.env` и конфиги `/etc/prometheus/*.yml`;
      - `monitoring-grafana.service` – использует `/etc/grafana/grafana.ini` и `/usr/share/grafana`;
      - `monitoring-harvest.service` – аналог системного `harvest.service`, но как user‑юнит;
      - `monitoring.target` – общий target для стека.
    - выставляет владельца `${KAE}-lnx-mon_sys` и права (700 на `.config`, 640 на юниты).
  - В `configure_services`:
    - если `${KAE}-lnx-mon_sys` существует, запуск/enable/проверка делается через `runuser -u ${KAE}-lnx-mon_sys -- env XDG_RUNTIME_DIR=/run/user/<uid> systemctl --user ...`;
    - если нет – используется fallback: системные юниты `prometheus` и `grafana-server` через обычный `systemctl`.
- **Что остаётся**:
  - На стороне админов ОС/RLM нужно:
    - создавать `${KAE}-lnx-mon_sys` с домашним каталогом;
    - включать `loginctl enable-linger ${KAE}-lnx-mon_sys`;
    - при необходимости добавлять в группу `systemd-journal`.
  - В будущей PROD‑схеме можно полностью отказаться от системных юнитов для Harvest внутри скрипта и оставить их на RLM.

4.2. *«Роли: СУЗ/ПУЗ/ТУЗ/RO»*
- **Статус**: ЧАСТИЧНО
- **Модель в проекте**:
  - `${KAE}-lnx-mon_sys` – СУЗ: владелец user‑юнитов мониторинга, под ним крутятся сервисы; без интерактивного логина.
  - `${KAE}-lnx-mon_ci` – ТУЗ: CI/деплой, выполняет скрипт/управляет user‑юнитами, но не админит ОС.
  - `${KAE}-lnx-mon_admin` – ПУЗ: интерактивный админ АС, может читать логи и управлять сервисами (через sudo -u mon_sys systemctl --user), без права менять бинарники.
  - `${KAE}-lnx-mon_ro` – RO: только чтение логов/конфигов.
  - `${KAE}-lnx-va-start` / `${KAE}-lnx-va-read` – сервисная УЗ и группа для Vault‑agent.
- **Что остаётся**:
  - Формально закрепить эту модель в `SECURITY_IB_NOTES.md` и в заявках IDM/RLM (описание УЗ/групп, их прав и точек монтирования).

======================================================================
5. Sudoers для схемы CI → mon_sys → user-юниты
======================================================================

5.1. *«Запуск команд от имени другого пользователя (включая nologin) через sudo -u, с ограниченным набором команд»*
- **Статус**: В БЭКЛОГЕ
- **Желаемая модель**:
  - Для CI‑пользователя `${KAE}-lnx-mon_ci` в sudoers описать права вида:
    - `${KAE}-lnx-mon_ci ALL=(${KAE}-lnx-mon_sys) NOPASSWD: /usr/bin/systemctl --user daemon-reload, /usr/bin/systemctl --user start monitoring-prometheus.service, /usr/bin/systemctl --user restart monitoring-prometheus.service, /usr/bin/systemctl --user start monitoring-grafana.service, /usr/bin/systemctl --user restart monitoring-grafana.service, /usr/bin/systemctl --user start monitoring-harvest.service, /usr/bin/systemctl --user restart monitoring-harvest.service, /usr/bin/systemctl --user start monitoring.target, /usr/bin/systemctl --user restart monitoring.target`.
  - В правилах sudoers никаких `*` и переменных – только конкретные пути и команды.
- **Текущее состояние**:
  - В репозитории есть минимальный `sudoers` с одним правилом на запуск скрипта от root (для DEV/переходного этапа).
  - Новая схема CI→mon_sys через `systemctl --user` пока не вынесена в отдельный фрагмент sudoers – это задача на согласование с ИБ/админами.

======================================================================
6. Работа с системными каталогами (/etc, /usr, /var) и очисткой
======================================================================

6.1. *«По возможности не использовать /usr, /var, /etc для прикладного ПО…»*
- **Статус**: ЧАСТИЧНО
- **Как реализовано**:
  - Прикладные данные и конфиги в основном лежат в `/opt/harvest`, `/opt/vault`, `/var/lib/monitoring_deployment_state`, `/opt/mon_distrib/...`.
  - Конфиги Prometheus/Grafana (`/etc/prometheus`, `/etc/grafana`) используются там, где ожидают vendor RPM и их юниты – это обоснованное исключение, так как перенести эти пути нельзя без нарушения поддержки.

6.2. *«Удаление логов, systemd‑юнитов и директории в /etc, /usr должно быть обосновано и желательно через RLM»*
- **Статус**: В БЭКЛОГЕ
- **Текущее состояние**:
  - В `cleanup_all_previous()` присутствует `rm -rf` для каталогов `/etc/prometheus`, `/etc/grafana`, `/opt/harvest`, `/usr/share/grafana`, `/usr/share/prometheus`, а также удаление юнитов из `/usr/lib/systemd/system` и `/etc/systemd/system`.
- **План**:
  - Вынести «полную очистку» в отдельный RLM‑сценарий (по аналогии с установкой RPM).
  - В самом `deploy_monitoring_script.sh` оставить только удаление своих временных файлов и, при необходимости, «мягкую» очистку прикладных каталогов в `/opt`.

======================================================================
7. Хранение и обработка секретов (SecMan / Vault)
======================================================================

7.1. *«Постоянное хранение секретов – в SecMan, временные файлы минимальны и защищены»*
- **Статус**: ЧАСТИЧНО / БЛИЗКО К РЕАЛИЗОВАНО
- **Как реализовано**:
  - RLM‑сценарий `vault_agent_config` настраивает Vault‑agent под `${KAE}-lnx-va-start`/`${KAE}-lnx-va-read`.
  - `setup_vault_config()` пишет `agent.hcl` и формирует `data_sec.json` с секретами (rpm_url, netapp_ssh, grafana_web, vault-agent, сертификаты) в `/opt/vault/conf`.
  - Скрипт читает секреты через `jq` из JSON‑файлов, **не выводя** их в терминал.
  - В конце `main()` выполняется `unset RLM_TOKEN GRAFANA_USER GRAFANA_PASSWORD GRAFANA_BEARER_TOKEN`.
- **Что остаётся**:
  - В `SECURITY_IB_NOTES.md` описать катало

